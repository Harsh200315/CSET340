# -*- coding: utf-8 -*-
"""lab11_part1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15xJimMsiWt8kGOD4bXu0VtsnEYFFZaNE
"""

import cv2
import numpy as np
import matplotlib.pyplot as plt
import networkx as nx
import urllib.request
import os
# Import the cv2_imshow function from google.colab.patches
from google.colab.patches import cv2_imshow

# Helper to download a sample image and video
sample_image_url = 'https://raw.githubusercontent.com/opencv/opencv/master/samples/data/lena.jpg'
sample_video_url = 'https://raw.githubusercontent.com/opencv/opencv/master/samples/data/vtest.avi'

if not os.path.exists('sample_image.jpg'):
    urllib.request.urlretrieve(sample_image_url, 'sample_image.jpg')
if not os.path.exists('sample_video.avi'):
    urllib.request.urlretrieve(sample_video_url, 'sample_video.avi')


########################
# Task 1.1 - Visual Saliency Detection
########################
print("--- Visual Saliency Detection ---")

# Load image
image = cv2.imread('sample_image.jpg')

# Initialize OpenCV Saliency algorithm
saliency = cv2.saliency.StaticSaliencyFineGrained_create()
success, saliencyMap = saliency.computeSaliency(image)

# Threshold the saliency map
saliencyMap = (saliencyMap * 255).astype("uint8")

# Use cv2_imshow instead of cv2.imshow
cv2_imshow(image) # Changed from cv2.imshow to cv2_imshow
cv2_imshow(saliencyMap) # Changed from cv2.imshow to cv2_imshow
cv2.waitKey(0)
cv2.destroyAllWindows()

# For video
print("Running Saliency Detection on Video...")
cap = cv2.VideoCapture('sample_video.avi')
while True:
    ret, frame = cap.read()
    if not ret:
        break
    success, saliencyMap = saliency.computeSaliency(frame)
    saliencyMap = (saliencyMap * 255).astype("uint8")
    # Use cv2_imshow instead of cv2.imshow
    cv2_imshow(frame) # Changed from cv2.imshow to cv2_imshow
    cv2_imshow(saliencyMap) # Changed from cv2.imshow to cv2_imshow
    if cv2.waitKey(30) & 0xFF == ord('q'):
        break
cap.release()
cv2.destroyAllWindows()

import cv2
import numpy as np
import matplotlib.pyplot as plt
from IPython.display import Video, display
import urllib.request
import os

# Helper to download a sample image and video
sample_image_url = 'https://raw.githubusercontent.com/opencv/opencv/master/samples/data/lena.jpg'
sample_video_url = 'https://raw.githubusercontent.com/opencv/opencv/master/samples/data/vtest.avi'

if not os.path.exists('sample_image.jpg'):
    urllib.request.urlretrieve(sample_image_url, 'sample_image.jpg')
if not os.path.exists('sample_video.avi'):
    urllib.request.urlretrieve(sample_video_url, 'sample_video.avi')

########################
# Task 1.1 - Visual Saliency Detection (image and full video)
########################
print("--- Visual Saliency Detection ---")

# Load image
image = cv2.imread('sample_image.jpg')

# Initialize OpenCV Saliency algorithm
saliency = cv2.saliency.StaticSaliencyFineGrained_create()
success, saliencyMap = saliency.computeSaliency(image)

# Threshold the saliency map
saliencyMap = (saliencyMap * 255).astype("uint8")

# Show image and saliency map
plt.figure(figsize=(10,5))
plt.subplot(1,2,1)
plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
plt.title('Original Image')
plt.axis('off')

plt.subplot(1,2,2)
plt.imshow(saliencyMap, cmap='gray')
plt.title('Saliency Map')
plt.axis('off')
plt.show()

# For video
print("Running Saliency Detection on Video and saving output...")

cap = cv2.VideoCapture('sample_video.avi')
fourcc = cv2.VideoWriter_fourcc(*'XVID')
out = cv2.VideoWriter('saliency_output.avi', fourcc, 20.0, (int(cap.get(3)), int(cap.get(4))), False)

while True:
    ret, frame = cap.read()
    if not ret:
        break
    success, saliencyMap = saliency.computeSaliency(frame)
    saliencyMap = (saliencyMap * 255).astype("uint8")
    out.write(saliencyMap)

cap.release()
out.release()

# Display saved saliency video
print("Displaying Saliency Output Video:")
display(Video('saliency_output.avi', embed=True, width=600, height=400))

print("--- Done with Visual Saliency ---")

print("--- Unsupervised Image Segmentation with K-Means ---")

# Load landscape image
img = cv2.imread('sample_image.jpg')
img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
Z = img.reshape((-1,3))

# Convert to np.float32
Z = np.float32(Z)

# Define criteria, number of clusters(K) and apply kmeans()
criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)
K = 4
ret,label,center=cv2.kmeans(Z,K,None,criteria,10,cv2.KMEANS_RANDOM_CENTERS)

# Now convert back into uint8 and make original image
center = np.uint8(center)
res = center[label.flatten()]
segmented_image = res.reshape((img.shape))

plt.figure(figsize=(10,5))
plt.subplot(121), plt.imshow(img)
plt.title('Original Image')
plt.axis('off')
plt.subplot(122), plt.imshow(segmented_image)
plt.title('Segmented Image (KMeans)')
plt.axis('off')
plt.show()

print("--- Graph Cut Segmentation ---")
# Import the networkx library
import networkx as nx

# Load image
img = cv2.imread('sample_image.jpg')
mask = np.zeros(img.shape[:2],np.uint8)

bgdModel = np.zeros((1,65),np.float64)
fgdModel = np.zeros((1,65),np.float64)

# Define a rectangle (manually for lena)
rect = (50,50,400,400)

# Apply grabCut
cv2.grabCut(img,mask,rect,bgdModel,fgdModel,5,cv2.GC_INIT_WITH_RECT)

# Create mask where sure background are 0, sure foreground are 1
mask2 = np.where((mask==2)|(mask==0),0,1).astype('uint8')
segmented_img = img*mask2[:,:,np.newaxis]

plt.figure(figsize=(12,5))
plt.subplot(121), plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
plt.title('Original Image')
plt.axis('off')
plt.subplot(122), plt.imshow(cv2.cvtColor(segmented_img, cv2.COLOR_BGR2RGB))
plt.title('GraphCut Segmented Image')
plt.axis('off')
plt.show()

# Visualizing the graph (just a simple illustration, not full graph)
print("Visualizing simplified graph structure...")
height, width = img.shape[:2]
G = nx.grid_2d_graph(height//10, width//10) # Use nx to access the grid_2d_graph function

pos = {(x,y):(y,-x) for x,y in G.nodes()}

plt.figure(figsize=(8,8))
nx.draw(G, pos=pos, # Use nx to access the draw function
        node_color='lightblue',
        with_labels=False,
        node_size=20,
        edge_color='gray')
plt.title('Simplified Graph Structure (Downsampled)')
plt.show()

print("--- DONE! ---")