# -*- coding: utf-8 -*-
"""cv_lab9.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1o3Yhq1Vhk_qEhzWC4jl8U9W5OBo80pTa
"""

import cv2
import numpy as np
from matplotlib import pyplot as plt

# Load the image with noise
image = cv2.imread('/content/Screenshot 2025-04-22 104809.png')
image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

# Denoising using fastNlMeansDenoisingColored
denoised_image = cv2.fastNlMeansDenoisingColored(cv2.cvtColor(image, cv2.COLOR_RGB2BGR), None, 10, 10, 7, 21) #no local mens denoising

# Show results
plt.figure(figsize=(10, 5))
plt.subplot(1, 2, 1), plt.imshow(image), plt.title("Original (Noisy)")
plt.subplot(1, 2, 2), plt.imshow(cv2.cvtColor(denoised_image, cv2.COLOR_BGR2RGB)), plt.title("Denoised")
plt.show()

from google.colab import files
import os

upload_folder = "/content/Pan_Images"
os.makedirs(upload_folder, exist_ok=True)

uploaded = files.upload()

for filename in uploaded.keys():
    os.rename(filename, os.path.join(upload_folder, filename))

!pip install imutils
# Import packages
from imutils import paths
import numpy as np
import imutils
import cv2
import matplotlib.pyplot as plt
import os

# ✅ Update this to your image folder path inside Colab or upload images
image_folder = "/content/Pan_Images"  # Replace with your folder path
output_path = "/content/stitched_output.jpg"

# Create list of image paths
imagePaths = sorted(list(paths.list_images(image_folder)))
images = []

print("[INFO] Loading images...")
for imagePath in imagePaths:
    image = cv2.imread(imagePath)
    if image is not None:
        images.append(image)

# Check if we have enough images
if len(images) < 2:
    print("[ERROR] Need at least 2 images to stitch!")
else:
    print("[INFO] Stitching images...")

    # Create stitcher object
    stitcher = cv2.Stitcher_create() if imutils.is_cv3() else cv2.Stitcher_create()

    # Perform stitching
    status, stitched = stitcher.stitch(images)

    if status == cv2.Stitcher_OK:
        print("[INFO] Stitching successful.")
        # Save stitched image
        cv2.imwrite(output_path, stitched)

        # Show image using matplotlib
        plt.figure(figsize=(15, 8))
        plt.axis("off")
        plt.title("Panorama")
        plt.imshow(cv2.cvtColor(stitched, cv2.COLOR_BGR2RGB))
        plt.show()
    else:
        print(f"[ERROR] Image stitching failed (status code: {status})")

import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.datasets import cifar10
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D
from tensorflow.keras.optimizers import Adam
# Import the PSNR function from the correct module
from skimage.metrics import peak_signal_noise_ratio as psnr # This line was changed

# Step 1: Load and Normalize CIFAR-10
(x_train, _), (x_test, _) = cifar10.load_data()
x_train = x_train.astype('float32') / 255.
x_test = x_test.astype('float32') / 255.

# Step 2: Add Gaussian Noise
def add_noise(data, noise_factor=0.2):
    noisy = data + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=data.shape)
    return np.clip(noisy, 0., 1.)

x_train_noisy = add_noise(x_train)
x_test_noisy = add_noise(x_test)

# Step 3: Build the Autoencoder
input_img = Input(shape=(32, 32, 3))

# Encoder
x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)
x = MaxPooling2D((2, 2), padding='same')(x)
x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)
encoded = MaxPooling2D((2, 2), padding='same')(x)

# Decoder
x = Conv2D(16, (3, 3), activation='relu', padding='same')(encoded)
x = UpSampling2D((2, 2))(x)
x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)
x = UpSampling2D((2, 2))(x)
decoded = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)

autoencoder = Model(input_img, decoded)
autoencoder.compile(optimizer=Adam(), loss='mse')

# Step 4: Train the Autoencoder
autoencoder.fit(x_train_noisy, x_train,
                epochs=20,
                batch_size=128,
                shuffle=True,
                validation_data=(x_test_noisy, x_test))

# Step 5: Predict Restored Images
decoded_imgs = autoencoder.predict(x_test_noisy)

# Step 6: Visualize Results
n = 5
plt.figure(figsize=(15, 6))
for i in range(n):
    # Original
    ax = plt.subplot(3, n, i + 1)
    plt.imshow(x_test[i])
    ax.set_title("Original")
    plt.axis("off")

    # Noisy
    ax = plt.subplot(3, n, i + n + 1)
    plt.imshow(x_test_noisy[i])
    ax.set_title("Noisy")
    plt.axis("off")

    # Restored
    ax = plt.subplot(3, n, i + 2*n + 1)
    plt.imshow(decoded_imgs[i])
    ax.set_title("Restored")
    plt.axis("off")
plt.tight_layout()
plt.show()

# Step 7: Evaluate with PSNR
psnr_scores = [psnr(x_test[i], decoded_imgs[i]) for i in range(100)]
print("Average PSNR over 100 test images:", np.mean(psnr_scores))

import tensorflow as tf
from tensorflow.keras import layers, models
import numpy as np
import matplotlib.pyplot as plt

# Fix seed for reproducibility
tf.random.set_seed(42)

# ----------- Load & Preprocess MNIST -----------
(x_train, _), _ = tf.keras.datasets.mnist.load_data()
x_train = (x_train.astype('float32') - 127.5) / 127.5  # Normalize to [-1, 1]
x_train = np.expand_dims(x_train, axis=-1)

# ----------- Build Generator -----------
def build_generator():
    model = models.Sequential([
        layers.Input(shape=(100,)),
        layers.Dense(7 * 7 * 128),
        layers.Reshape((7, 7, 128)),
        layers.BatchNormalization(),
        layers.ReLU(),
        layers.UpSampling2D(),
        layers.Conv2D(128, kernel_size=3, padding="same"),
        layers.BatchNormalization(),
        layers.ReLU(),
        layers.UpSampling2D(),
        layers.Conv2D(1, kernel_size=3, padding="same", activation='tanh')
    ])
    return model

# ----------- Build Discriminator -----------
def build_discriminator():
    model = models.Sequential([
        layers.Input(shape=(28, 28, 1)),
        layers.Conv2D(64, kernel_size=3, strides=2, padding="same"),
        layers.LeakyReLU(0.2),
        layers.Dropout(0.3),
        layers.Conv2D(128, kernel_size=3, strides=2, padding="same"),
        layers.LeakyReLU(0.2),
        layers.Dropout(0.3),
        layers.Flatten(),
        layers.Dense(1, activation='sigmoid')
    ])
    return model

# ----------- Training Function -----------
def train_gan(dataset, generator, discriminator, epochs=3, batch_size=128):
    cross_entropy = tf.keras.losses.BinaryCrossentropy()
    g_optimizer = tf.keras.optimizers.Adam(1e-4)
    d_optimizer = tf.keras.optimizers.Adam(1e-4)

    g_losses, d_losses = [], []

    for epoch in range(epochs):
        for i in range(0, len(dataset), batch_size):
            real_imgs = dataset[i:i + batch_size]
            batch_len = real_imgs.shape[0]
            noise = tf.random.normal([batch_len, 100])

            with tf.GradientTape() as disc_tape:
                fake_imgs = generator(noise, training=True)
                real_output = discriminator(real_imgs, training=True)
                fake_output = discriminator(fake_imgs, training=True)

                real_loss = cross_entropy(tf.ones_like(real_output), real_output)
                fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)
                d_loss = real_loss + fake_loss

            grads_d = disc_tape.gradient(d_loss, discriminator.trainable_variables)
            d_optimizer.apply_gradients(zip(grads_d, discriminator.trainable_variables))

            with tf.GradientTape() as gen_tape:
                fake_imgs = generator(noise, training=True)
                fake_output = discriminator(fake_imgs, training=True)
                g_loss = cross_entropy(tf.ones_like(fake_output), fake_output)

            grads_g = gen_tape.gradient(g_loss, generator.trainable_variables)
            g_optimizer.apply_gradients(zip(grads_g, generator.trainable_variables))

        g_losses.append(g_loss.numpy())
        d_losses.append(d_loss.numpy())
        print(f"Epoch {epoch+1}/{epochs} — D Loss: {d_loss:.4f}, G Loss: {g_loss:.4f}")

    return g_losses, d_losses, generator

# ----------- Visualization Functions -----------
def plot_generated_images(generator):
    noise = tf.random.normal([10, 100])
    gen_imgs = generator.predict(noise)
    gen_imgs = (gen_imgs + 1) / 2.0  # Scale to [0, 1]

    plt.figure(figsize=(15, 2))
    for i in range(10):
        plt.subplot(1, 10, i+1)
        plt.imshow(gen_imgs[i, :, :, 0], cmap='gray')
        plt.axis("off")
    plt.suptitle("Generated MNIST Digits (3 Epochs)")
    plt.tight_layout()
    plt.show()

def plot_loss_curves(g_losses, d_losses):
    plt.plot(g_losses, label="Generator Loss")
    plt.plot(d_losses, label="Discriminator Loss")
    plt.title("GAN Loss Over 3 Epochs")
    plt.xlabel("Epoch")
    plt.ylabel("Loss")
    plt.legend()
    plt.grid(True)
    plt.show()

# ----------- Run Training -----------
generator = build_generator()
discriminator = build_discriminator()

g_losses, d_losses, trained_generator = train_gan(x_train, generator, discriminator, epochs=3)
plot_generated_images(trained_generator)
plot_loss_curves(g_losses, d_losses)

!pip install --upgrade tensorflow-datasets
import tensorflow as tf
import tensorflow_datasets as tfds
import numpy as np
import matplotlib.pyplot as plt

# === Load Dataset ===
# Removed 'version' argument, relying on latest version
dataset, info = tfds.load('oxford_iiit_pet', with_info=True, data_dir='/content/dataset')
train_ds = dataset['train']
test_ds = dataset['test']

# === Constants ===
IMG_SIZE = 128
BATCH_SIZE = 32

# === Preprocessing Function ===
def preprocess(datapoint):
    image = tf.image.resize(datapoint['image'], (IMG_SIZE, IMG_SIZE)) / 255.0
    mask = tf.image.resize(datapoint['segmentation_mask'], (IMG_SIZE, IMG_SIZE))
    # Cast 'mask' to int32 before using tf.where
    mask = tf.cast(mask, tf.int32)
    mask = tf.where(mask == 2, 1, mask)  # merge class 2 into pet class (1)
    return image, tf.cast(mask, tf.uint8)

train = train_ds.map(preprocess).cache().shuffle(1000).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)
test = test_ds.map(preprocess).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)

def unet_model(input_size=(128, 128, 3)):
    inputs = tf.keras.Input(input_size)

    # Encoder
    c1 = tf.keras.layers.Conv2D(16, 3, activation='relu', padding='same')(inputs)
    c1 = tf.keras.layers.Conv2D(16, 3, activation='relu', padding='same')(c1)
    p1 = tf.keras.layers.MaxPooling2D()(c1)

    c2 = tf.keras.layers.Conv2D(32, 3, activation='relu', padding='same')(p1)
    c2 = tf.keras.layers.Conv2D(32, 3, activation='relu', padding='same')(c2)
    p2 = tf.keras.layers.MaxPooling2D()(c2)

    c3 = tf.keras.layers.Conv2D(64, 3, activation='relu', padding='same')(p2)
    c3 = tf.keras.layers.Conv2D(64, 3, activation='relu', padding='same')(c3)
    p3 = tf.keras.layers.MaxPooling2D()(c3)

    # Bottleneck
    c4 = tf.keras.layers.Conv2D(128, 3, activation='relu', padding='same')(p3)
    c4 = tf.keras.layers.Conv2D(128, 3, activation='relu', padding='same')(c4)

    # Decoder
    u1 = tf.keras.layers.UpSampling2D()(c4)
    concat1 = tf.keras.layers.Concatenate()([u1, c3])
    c5 = tf.keras.layers.Conv2D(64, 3, activation='relu', padding='same')(concat1)

    u2 = tf.keras.layers.UpSampling2D()(c5)
    concat2 = tf.keras.layers.Concatenate()([u2, c2])
    c6 = tf.keras.layers.Conv2D(32, 3, activation='relu', padding='same')(concat2)

    u3 = tf.keras.layers.UpSampling2D()(c6)
    concat3 = tf.keras.layers.Concatenate()([u3, c1])
    c7 = tf.keras.layers.Conv2D(16, 3, activation='relu', padding='same')(concat3)

    outputs = tf.keras.layers.Conv2D(1, 1, activation='sigmoid')(c7)

    return tf.keras.Model(inputs, outputs)

model = unet_model()
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
model.summary()

# === Train Model ===
history = model.fit(train, validation_data=test, epochs=3)

# === Predict Sample Masks ===
def show_sample_predictions(dataset, model, num=3):
    for images, masks in dataset.take(1):
        preds = model.predict(images)
        for i in range(num):
            plt.figure(figsize=(10, 3))
            plt.subplot(1, 3, 1)
            plt.imshow(images[i])
            plt.title("Image")
            plt.subplot(1, 3, 2)
            plt.imshow(tf.squeeze(masks[i]), cmap='gray')
            plt.title("True Mask")



show_sample_predictions(test, model)

