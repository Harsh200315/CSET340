{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Lab 11 - Part 1\n",
        "Visual Saliency Detection, K-Means Segmentation, and GraphCut Segmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import networkx as nx\n",
        "import urllib.request\n",
        "import os\n",
        "from IPython.display import Video, display\n",
        "from google.colab.patches import cv2_imshow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download resources if they don't exist\n",
        "sample_image_url = 'https://raw.githubusercontent.com/opencv/opencv/master/samples/data/lena.jpg'\n",
        "sample_video_url = 'https://raw.githubusercontent.com/opencv/opencv/master/samples/data/vtest.avi'\n",
        "\n",
        "if not os.path.exists('sample_image.jpg'):\n",
        "    urllib.request.urlretrieve(sample_image_url, 'sample_image.jpg')\n",
        "if not os.path.exists('sample_video.avi'):\n",
        "    urllib.request.urlretrieve(sample_video_url, 'sample_video.avi')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"--- Visual Saliency Detection ---\")\n",
        "\n",
        "# Load image\n",
        "image = cv2.imread('sample_image.jpg')\n",
        "\n",
        "# Initialize OpenCV Saliency algorithm\n",
        "saliency = cv2.saliency.StaticSaliencyFineGrained_create()\n",
        "success, saliencyMap = saliency.computeSaliency(image)\n",
        "\n",
        "# Threshold the saliency map\n",
        "saliencyMap = (saliencyMap * 255).astype(\"uint8\")\n",
        "\n",
        "cv2_imshow(image)\n",
        "cv2_imshow(saliencyMap)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Saliency Detection on Video\n",
        "print(\"Running Saliency Detection on Video...\")\n",
        "cap = cv2.VideoCapture('sample_video.avi')\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "    success, saliencyMap = saliency.computeSaliency(frame)\n",
        "    saliencyMap = (saliencyMap * 255).astype(\"uint8\")\n",
        "    cv2_imshow(frame)\n",
        "    cv2_imshow(saliencyMap)\n",
        "    if cv2.waitKey(30) & 0xFF == ord('q'):\n",
        "        break\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Saliency Detection for Full Video and Save\n",
        "print(\"Running Saliency Detection on Video and saving output...\")\n",
        "cap = cv2.VideoCapture('sample_video.avi')\n",
        "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
        "out = cv2.VideoWriter('saliency_output.avi', fourcc, 20.0, (int(cap.get(3)), int(cap.get(4))), False)\n",
        "\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "    success, saliencyMap = saliency.computeSaliency(frame)\n",
        "    saliencyMap = (saliencyMap * 255).astype(\"uint8\")\n",
        "    out.write(saliencyMap)\n",
        "\n",
        "cap.release()\n",
        "out.release()\n",
        "\n",
        "print(\"Displaying Saliency Output Video:\")\n",
        "display(Video('saliency_output.avi', embed=True, width=600, height=400))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# K-Means Segmentation\n",
        "print(\"--- Unsupervised Image Segmentation with K-Means ---\")\n",
        "img = cv2.imread('sample_image.jpg')\n",
        "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "Z = img.reshape((-1,3))\n",
        "Z = np.float32(Z)\n",
        "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
        "K = 4\n",
        "ret,label,center=cv2.kmeans(Z,K,None,criteria,10,cv2.KMEANS_RANDOM_CENTERS)\n",
        "center = np.uint8(center)\n",
        "res = center[label.flatten()]\n",
        "segmented_image = res.reshape((img.shape))\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.subplot(121), plt.imshow(img)\n",
        "plt.title('Original Image')\n",
        "plt.axis('off')\n",
        "plt.subplot(122), plt.imshow(segmented_image)\n",
        "plt.title('Segmented Image (KMeans)')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Graph Cut Segmentation\n",
        "print(\"--- Graph Cut Segmentation ---\")\n",
        "img = cv2.imread('sample_image.jpg')\n",
        "mask = np.zeros(img.shape[:2],np.uint8)\n",
        "bgdModel = np.zeros((1,65),np.float64)\n",
        "fgdModel = np.zeros((1,65),np.float64)\n",
        "rect = (50,50,400,400)\n",
        "cv2.grabCut(img,mask,rect,bgdModel,fgdModel,5,cv2.GC_INIT_WITH_RECT)\n",
        "mask2 = np.where((mask==2)|(mask==0),0,1).astype('uint8')\n",
        "segmented_img = img*mask2[:,:,np.newaxis]\n",
        "plt.figure(figsize=(12,5))\n",
        "plt.subplot(121), plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "plt.title('Original Image')\n",
        "plt.axis('off')\n",
        "plt.subplot(122), plt.imshow(cv2.cvtColor(segmented_img, cv2.COLOR_BGR2RGB))\n",
        "plt.title('GraphCut Segmented Image')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Graph Visualization\n",
        "print(\"Visualizing simplified graph structure...\")\n",
        "height, width = img.shape[:2]\n",
        "G = nx.grid_2d_graph(height//10, width//10)\n",
        "pos = {(x,y):(y,-x) for x,y in G.nodes()}\n",
        "plt.figure(figsize=(8,8))\n",
        "nx.draw(G, pos=pos, node_color='lightblue', with_labels=False, node_size=20, edge_color='gray')\n",
        "plt.title('Simplified Graph Structure (Downsampled)')\n",
        "plt.show()\n",
        "print(\"--- DONE! ---\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}